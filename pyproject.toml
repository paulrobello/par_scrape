[project]
name = "par_scrape"
dynamic = [
    "version",
]
description = "A versatile web scraping tool with options for Selenium or Playwright, featuring OpenAI-powered data extraction and formatting."
url = "https://github.com/paulrobello/par_scrape"
readme = "README.md"
requires-python = ">=3.10"
authors = [
    { name = "Paul Robello", email = "probello@gmail.com" },
]
maintainers = [
    { name = "Paul Robello", email = "probello@gmail.com" },
]
classifiers = [
    "License :: OSI Approved :: MIT License",
    "Environment :: Console",
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: End Users/Desktop",
    "Intended Audience :: Other Audience",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Operating System :: MacOS",
    "Operating System :: Microsoft :: Windows :: Windows 10",
    "Operating System :: Microsoft :: Windows :: Windows 11",
    "Operating System :: POSIX :: Linux",
    "Topic :: Internet :: WWW/HTTP :: Browsers",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Text Processing :: Markup :: HTML",
    "Typing :: Typed",
]
keywords = [
    "web scraping",
    "data extraction",
    "selenium",
    "playwright",
    "openai",
    "anthropic",
    "xai",
    "openrouter",
    "groq",
    "ollama",
    "llamacpp",
]
dependencies = [
    "beautifulsoup4>=4.13.3",
    "pandas>=2.2.3",
    "pydantic>=2.10.6",
    "python-dotenv>=1.0.1",
    "rich>=13.9.4",
    "typer>=0.15.1",
    "openpyxl>=3.1.5",
    "tabulate>=0.9.0",
    "par-ai-core>=0.1.20",
    "fastapi>=0.115.8",
    "tldextract>=5.1.3",
    "strenum>=0.4.15",
]
packages = [
    "src/par_scrape",
]

[project.license]
file = "LICENSE"

[project.urls]
Homepage = "https://github.com/paulrobello/par_scrape"
Documentation = "https://github.com/paulrobello/par_scrape/blob/main/README.md"
Repository = "https://github.com/paulrobello/par_scrape"
Issues = "https://github.com/paulrobello/par_scrape/issues"
Discussions = "https://github.com/paulrobello/par_scrape/discussions"
Wiki = "https://github.com/paulrobello/par_scrape/wiki"

[project.scripts]
par_scrape = "par_scrape.__main__:app"

[build-system]
requires = [
    "hatchling",
    "wheel",
]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
    "build>=1.2.1",
    "twine>=6.1.0",
    "pyright>=1.1.379",
    "ruff>=0.9.6",
    "pre-commit>=4.1.0",
]

[tool.hatch.version]
path = "src/par_scrape/__init__.py"

[tool.hatch.build.targets.wheel]
packages = [
    "src/par_scrape",
]
include = [
    "py.typed",
    "**/*.py",
    "**/*.html",
    "**/*.gif",
    "**/*.jpg",
    "**/*.png",
    "**/*.md",
]

[tool.hatch.build.targets.sdist]
include = [
    "src/par_scrape",
    "LICENSE",
    "README.md",
    "extraction_prompt.md",
    "pyproject.toml",
]
exclude = [
    "*.pyc",
    "__pycache__",
    "*.so",
    "*.dylib",
]
